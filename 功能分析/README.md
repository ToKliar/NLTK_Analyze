# 功能分析

这部分对NLTK库的功能进行分析 

## NLTK的主要模块和功能 

下面两个表展示了NLTK包下的各个子包和子模块的功能和对应的自然语言处理任务 （按照字典序排序）  

对于NLTK包功能的详细分析聚焦于主要的自然语言处理任务 

| NLTK的子包   | 自然语言处理任务 | 功能                                             |
|-----------|----------|------------------------------------------------|
| app       | 应用       | 图形化交互式NLTK工具                                   |
| ccg       | 语义解析     | 组合范畴文法                                         |
| chat      | 应用       | 聊天机器人                                          |
| chunk     | 分块       | 使用正则表达式、n-gram、命名实体等方式进行分块                     |
| classify  | 分类任务     | 对文本进行分类（打标签）                                   |
| cluster   | 聚类任务     | K-means、EM、GAAC方法对文本进行聚类                       |
| corpus    | 访问语料库    | 通过该模块访问NLTK提供的语料库和词典                           |
| draw      | 应用       | 绘制NLTK的解析树                                     |
| inference | 语义解释     | 用于定理证明和模型检验                                    |
| lm        | 语言模型     | 目前只包含n-gram模型                                  |
| metrics   | 指标评估     | 对自然语言处理结果使用召回率等指标进行评估                          |
| parse     | 语法解析     | 使用图表或概率解析的方式生成语法树                              |
| sem       | 语义解释     | 使用一阶逻辑公式表示语义结构，在集合理论模型中进行评估                    |
| sentiment | 情感分析     | 使用NLTK内置特征和分类器对文本进行情感分析                        |
| stem      | 词干提取     | 抽取词的词干或词根形式                                    |
| tag       | 词性标注     | 使用n-gram，backoff，HMM等算法进行词性标注                  |
| tbl       | 机器学习     | 基于转换的机器学习(Transformation Based)，被BrillTagger使用 |
| test      | 测试       | NLTK内模块的单元测试                                   |
| tokenize  | 词元化      | 将文本按照不同粒度划分                                    |
| translate | 机器翻译     | 用于机器翻译任务的特征                                    |
| tree      | 文本结构     | 用于表示文本的语言结构，如语法树                               |
| twitter   | 应用       | 使用Twitter API检索Tweet文档                         |


| NLTK的子模块          | 功能                                  |
|-------------------|-------------------------------------|
| book              | NLTK的指导书                            |
| cli               | NLTK的命令行工具                          |
| collections       | NLTK实现的collection                   |
| collocations      | 识别词组的工具                             |
| compat            | 版本兼容                                |
| data              | 查找和加载NLTK提供的资源                      |
| decorators        | NLTK内置的decorator                    |
| downloader        | NLTK语料库和模块下载器                       |
| featstruct        | 文本特征结构的基本数据类和对特征结构进行基本操作的类          |
| grammar           | 表示上下文无关语法的基本数据类。                    |
| help              | NLTK使用帮助                            |
| internals         | NLTK内置的与java、字符串交互的工具               |
| jsontags          | 给数据打上JSON标记，便于downloader查找文件        |
| lazyimport        | 延迟模块导入，加速启动时间                       |
| probability       | 表示和处理概率信息的类                         |
| text              | 各种用于文本分析的功能：索引、正则表达式搜索等             |
| tgrep             | 用Tgrep算法搜索NLTK中的树结构                 |
| toolbox           | 用于读取、写入和操作工具箱数据库和设置文件，处理SIL工具箱格式的数据 |
| treeprettyprinter | 对于NLTK中树结构的漂亮的绘制                    |
| treetransforms    | 解析自然语言中的语法转换的方法集合                   |
| util              | 一些实用方法                              |
| wsd               | 为上下文中的歧义单词返回一个同义词集                  |

## 分析过程

本部分主要参考的资料是NLTK的官方指导书 ![NLTK BOOK](https://www.nltk.org/book/)

进行一个分类任务的简单流程可以参考[简单流程](./simple.ipynb)

对于自然语言的处理的大致流程如下：

### 文本获取  
获取某一自然语言处理任务需要的文本，NLTK提供了大量的语料库适用于不同的自然语言处理任务，并提供接口下载这些语料库。可以通过corpus模块去访问语料库，以对象的方式读取语料库内的文本和附加的处理（词性标注、标签等）。对于corpus模块的介绍在[corpus 模块介绍](./corpus.ipynb)中

### 文本处理
获得文本后是要对文本的格式等做一个规范化，将HTML等格式的文本转换为字符串形式，接下来要从文本中获取信息。

NLTK可以通过将文本转换为Text对象进行索引、查找等一系列操作

从文本中获取信息的简单流程在[文本信息提取流程](./extract_information.ipynb)中 

```
NLTK不支持对中文进行分句、分词、词性标注等预处理操作，推荐的库有jieba
```

### 文本分句

第一步是将文本划分为句子，这部分和分词的代码都在NLTK的tokenizer模块中实现

相关的示例见[分词和分句](./tokenize.ipynb)

### 文本分词 

文本分句之后使用词元化方法将句子划分为词（token），使得文本变为token序列

分完词后可以对文本中的词进行简单统计分析，相关示例在[统计分析](./statistic.ipynb)

### 词性标注

对于token序列可以进行一系列的操作帮助进一步分析句子的结构和语义，提取文本的特征  

基本的任务就是词性标注，根据token的性质给token序列中每一个token打上标签（tag）  

NLTK在tag模块中根据多种机器学习算法实现了多种Tagger，对应的示例在[词性标注](./tag.ipynb)中

### 词干提取和词性还原

词干提取和词性还原是将词标准化的过程  

词性还原是将词变为最基础的形态，词干提取则是去除词缀，获得词根的过程 

NLTK将这两部分集成在stem模块中，相关示例在[词的标准化](./lemma_stem.ipynb)

### 分块

基于token序列，可以对token序列进行分块，如将组成名词短语、动词短语的词分在一起，对token序列进行命名实体识别任务等  

NLTK在chunk模块中实现了分块的功能，对应的示例在[分块](./chunk.ipynb)中

### 句法分析

句法分析分析句子的句法结构（主谓宾结构）和词汇间的依存关系，从而为语义分析、情感分析等自然语言任务打基础 

NLTK在Parser模块中实现句法分析的功能，可以将句子转变为语法树，展示句子的语法结构

相关示例代码在[句法分析](./sentence_structure.ipynb)中

### 语义分析

自然语言处理中对句子进行语义分析，分为两部分：

词汇级语义分析：对词的含义进行分析，主要是消除词在句子中的歧义，找到词在句中最合适的语义 

关于词汇的含义，NLTK提供了WordNet语料库，该语料库包含了词汇的含义，在含义层面上对词与词之间的关系使用层级结构进行表示  
对于WordNet的使用的示例，在[语料库](./corpus.ipynb)中的后半部分

句子级语义分析：对于句子整体的含义进行分析  
NLTK中对于句子可以通过命题逻辑分析其语义，对其进行验证和推理 
对应的示例在[命题逻辑](./analyze_meaning.ipynb)中

### 分类器

基于上述对自然语言文本的分析，可以从文本中提取特征从而对文本进行分类，如情感分析等  

NLTK在classifer模块中根据多种机器学习算法实现了不同的Classifier，同时提供接口封装使用Scikit-Learn机器学习库中的分类器 

相关示例代码在[分类](./classify.ipynb)中




